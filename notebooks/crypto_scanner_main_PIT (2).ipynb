{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Google Drive Bibliothek installieren\n",
        "!pip install -U google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib\n"
      ],
      "metadata": {
        "id": "RS8yZpB0-tIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdf3a54d"
      },
      "outputs": [],
      "source": [
        "# 1 Repo klonen oder aktualisieren\n",
        "\n",
        "import os\n",
        "\n",
        "REPO_DIR = \"/content/colabtool\"\n",
        "REPO_URL = \"https://github.com/schluchtenscheisser/colabtool.git\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone $REPO_URL $REPO_DIR\n",
        "else:\n",
        "    %cd $REPO_DIR\n",
        "    !git pull\n",
        "    %cd -\n",
        "!pip install -r /content/colabtool/requirements.txt\n",
        "\n",
        "# Alte Zelle\n",
        "# %pip install -U \"git+https://github.com/schluchtenscheisser/colabtool@main\"\n",
        "# import importlib, colabtool\n",
        "# importlib.reload(colabtool)\n",
        "# print(\"installiert:\", colabtool.__file__)\n",
        "# import os\n",
        "# print(\"Geladen aus:\", os.path.abspath(colabtool.__file__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d4f3aaa"
      },
      "outputs": [],
      "source": [
        "# 2 Module importieren\n",
        "import sys\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "\n",
        "# Pfad zu deinem Repo\n",
        "MODULE_PATH = \"/content/colabtool/src\"\n",
        "sys.path.insert(0, MODULE_PATH)\n",
        "\n",
        "# Automatisch alle .py-Dateien in colabtool importieren\n",
        "pkg_name = \"colabtool\"\n",
        "pkg_path = Path(MODULE_PATH) / pkg_name\n",
        "all_modules = [f.stem for f in pkg_path.glob(\"*.py\") if f.name != \"__init__.py\"]\n",
        "\n",
        "globals()[pkg_name] = importlib.import_module(pkg_name)\n",
        "for mod_name in all_modules:\n",
        "    full_mod_name = f\"{pkg_name}.{mod_name}\"\n",
        "    globals()[mod_name] = importlib.import_module(full_mod_name)\n",
        "    print(f\"‚úÖ geladen: {full_mod_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c15ff9d"
      },
      "outputs": [],
      "source": [
        "# 3 Modul-Version validieren\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "import sys\n",
        "import time\n",
        "\n",
        "def reload_and_log(modname: str):\n",
        "    if modname in sys.modules:\n",
        "        mod = sys.modules[modname]\n",
        "        path = Path(mod.__file__)\n",
        "        mod_time = time.ctime(path.stat().st_mtime)\n",
        "        importlib.reload(mod)\n",
        "        print(f\"üîÅ Reloaded {modname} | üìÑ {path.name} | üïí {mod_time}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Modul {modname} nicht geladen\")\n",
        "\n",
        "# Hauptmodul zuerst\n",
        "reload_and_log(\"colabtool\")\n",
        "\n",
        "# Alle geladenen colabtool-Submodule reloaded dynamisch\n",
        "pkg_prefix = \"colabtool.\"\n",
        "for name in sorted(sys.modules):\n",
        "    if name.startswith(pkg_prefix) and name != \"colabtool\":\n",
        "        reload_and_log(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "466744a0"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "from colabtool.export import _safe_col_width\n",
        "print(inspect.getsource(_safe_col_width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8470c257"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "from colabtool import export\n",
        "print(inspect.getsource(export))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e98443a"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "from colabtool.features import compute_feature_block\n",
        "\n",
        "print(inspect.getsource(compute_feature_block))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload-Code um Dateien hochzuladen (bei Bedarf auskommentieren)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.upload()\n"
      ],
      "metadata": {
        "id": "Nhv3JgSwASfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef38b235"
      },
      "outputs": [],
      "source": [
        "# Crypto-Scanner Main (v14.5) ‚Äî Free-CG stabil, Chart-Cache, Hybrid-Kategorien, Cap 50‚Äì1000 Mio, Buzz-Audit\n",
        "\n",
        "# === Bootstrap: Pakete, Drive, Pfade ===\n",
        "import os\n",
        "\n",
        "# === Logging/Warnungen ===\n",
        "import logging as _rootlog, warnings, numpy as _np, pandas as _pd\n",
        "_rootlog.basicConfig(level=_rootlog.INFO, format='[%(asctime)s] [%(levelname)s] %(message)s')\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "_pd.options.mode.chained_assignment = None\n",
        "_np.seterr(all=\"ignore\")\n",
        "\n",
        "# === ENV (Free-Plan) ===\n",
        "os.environ.update({\n",
        "    \"COINGECKO_API_KEY\": \"CG-iM4aTeNWTc2kR2DSLEsTXWui\",\n",
        "    \"CG_FORCE_FREE\": \"1\",\n",
        "    \"CG_SKIP_AFTER_429\": \"1\",\n",
        "    \"CG_MAX_ATTEMPTS\": \"1\",\n",
        "    \"CG_MIN_INTERVAL_S\": \"3.5\",\n",
        "    \"CG_CATS_TIME_BUDGET_S\": \"120\",\n",
        "    \"PROVIDERS_CATS_TIME_BUDGET_S\": \"90\",\n",
        "    \"SKIP_CATEGORIES\": os.getenv(\"SKIP_CATEGORIES\", \"0\"),\n",
        "    \"REQUIRE_MEXC\": os.getenv(\"REQUIRE_MEXC\", \"1\"),\n",
        "    \"LIGHT_BREAKOUT_ALL\": os.getenv(\"LIGHT_BREAKOUT_ALL\", \"0\"),\n",
        "    \"ALLOW_CG_FALLBACK\": os.getenv(\"ALLOW_CG_FALLBACK\", \"0\"),\n",
        "    \"BUZZ_HALF_LIFE_H\": os.getenv(\"BUZZ_HALF_LIFE_H\", \"48\"),\n",
        "    \"BUZZ_PUBLISHER_WEIGHTS\": os.getenv(\"BUZZ_PUBLISHER_WEIGHTS\", '{\"coindesk\":1.0,\"cointelegraph\":1.0,\"theblock\":1.1,\"decrypt\":0.9}')\n",
        "})\n",
        "# Optional Fallback-Provider:\n",
        "# os.environ[\"CMC_API_KEY\"] = \"...\"\n",
        "# os.environ[\"MESSARI_API_KEY\"] = \"...\"\n",
        "# os.environ[\"COINPAPRIKA_API_KEY\"] = \"...\"\n",
        "\n",
        "# === Imports aus Modulen ===\n",
        "from colabtool.utils import logging, time, datetime, timezone, pd, np\n",
        "from colabtool.data_sources import cg_markets, map_tvl, update_seen_ids, cg_market_chart\n",
        "from colabtool.pre_universe import apply_pre_universe_filters\n",
        "from colabtool.exchanges import apply_mexc_filter, export_mexc_seed_template\n",
        "from colabtool.features import compute_feature_block, exclusion_mask, peg_like_mask, tag_segment\n",
        "from colabtool.scores import score_block, compute_early_score\n",
        "from colabtool.breakout import compute_breakout_for_ids\n",
        "from colabtool.buzz import add_buzz_metrics_for_candidates\n",
        "from colabtool.backtest import backtest_on_snapshot\n",
        "from colabtool.export import write_sheet, write_meta_sheet\n",
        "from colabtool.export_helpers import make_fulldata\n",
        "from colabtool.category_providers import enrich_categories_hybrid\n",
        "from colabtool.cg_cache_patch import setup_cg_chart_cache\n",
        "\n",
        "# ASOF_Date definieren\n",
        "from datetime import datetime\n",
        "ASOF_DATE = datetime.today().strftime(\"%Y%m%d\")\n",
        "\n",
        "# Lokaler Cache statt Google Drive\n",
        "os.environ[\"CACHE_DIR\"] = \"/content/cache/http_cache\"\n",
        "\n",
        "# Pfade und Verzeichnisse\n",
        "import os\n",
        "#from google.colab import drive\n",
        "#\n",
        "#MOUNTPOINT = \"/content/drive\"\n",
        "#\n",
        "# Wenn bereits gemountet: nicht erneut mounten\n",
        "#if not os.path.ismount(MOUNTPOINT):\n",
        "    # Wenn dort Dateien liegen ‚Üí manuelles Cleanup erforderlich\n",
        "    #if os.path.exists(MOUNTPOINT) and os.listdir(MOUNTPOINT):\n",
        "        #raise RuntimeError(f\"‚ùå Fehler: {MOUNTPOINT} enth√§lt bereits Dateien. Bitte Notebook neu starten.\")\n",
        "\n",
        "    #drive.mount(MOUNTPOINT, force_remount=True)\n",
        "\n",
        "# Tempor√§re Pfade und Verzeichnisse\n",
        "\n",
        "EXPORT_DIR = \"/content/snapshots/exports\"\n",
        "CACHE_DIR  = \"/content/snapshots/cache\"\n",
        "\n",
        "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "assert os.path.exists(EXPORT_DIR), f\"‚ùå Export-Verzeichnis nicht gefunden: {EXPORT_DIR}\"\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "# === CG: /coins/{id}/market_chart Cache aktivieren (24h) ===\n",
        "setup_cg_chart_cache(cache_dir=os.path.join(CACHE_DIR, \"cg_chart\"), ttl_hours=24)\n",
        "\n",
        "# === CG Smart-Get: Robust gegen Reload & Rekursion ===\n",
        "import time as _time, requests as _requests\n",
        "from colabtool import data_sources as ds\n",
        "\n",
        "# Nur patchen, wenn noch nicht gepatcht\n",
        "if not hasattr(ds, \"_ORIG_CG_GET\"):\n",
        "    ds._ORIG_CG_GET = ds._cg_get  # Original sichern (nur 1x)\n",
        "\n",
        "def _cg_get_smart(path, params=None):\n",
        "    if path.strip().lower() == \"/coins/markets\":\n",
        "        return ds._ORIG_CG_GET(path, params=params)\n",
        "    key = os.getenv(\"COINGECKO_API_KEY\", \"\").strip()\n",
        "    free = os.getenv(\"CG_FORCE_FREE\", \"1\") == \"1\" or not key\n",
        "    base = \"https://api.coingecko.com/api/v3\" if free else \"https://pro-api.coingecko.com/api/v3\"\n",
        "    headers = {\"Accept\": \"application/json\", \"User-Agent\": \"cg-screener/1.0\"}\n",
        "    if not free and key:\n",
        "        headers[\"x-cg-pro-api-key\"] = key\n",
        "    q = dict(params or {})\n",
        "    min_interval = float(os.getenv(\"CG_MIN_INTERVAL_S\", \"3.5\"))\n",
        "    last = getattr(ds, \"_CG_LAST_CALL_TS\", None)\n",
        "    if last is not None:\n",
        "        delta = _time.perf_counter() - last\n",
        "        if delta < min_interval:\n",
        "            _time.sleep(min_interval - delta)\n",
        "    url = f\"{base}{path}\"\n",
        "    try:\n",
        "        sess = getattr(ds, \"_SESSION\", None)\n",
        "        r = (sess or _requests).get(url, headers=headers, params=q, timeout=20)\n",
        "        ds._CG_LAST_CALL_TS = _time.perf_counter()\n",
        "    except Exception as ex:\n",
        "        ds.logging.warning(f\"[cg-smart] net err on {url}: {ex}\")\n",
        "        return {}\n",
        "    if r.status_code == 429:\n",
        "        ds.logging.warning(f\"[cg-smart] 429 on {url} ‚Üí skip\")\n",
        "        return {}\n",
        "    if r.status_code != 200:\n",
        "        ds.logging.warning(f\"[cg-smart] HTTP {r.status_code} on {url}\")\n",
        "        try:\n",
        "            return r.json() if r.content else {}\n",
        "        except Exception:\n",
        "            return {}\n",
        "    try:\n",
        "        return r.json()\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "# Patch aktivieren\n",
        "ds._cg_get = _cg_get_smart\n",
        "\n",
        "\n",
        "# === Lokaler Fallback f√ºr /coins/markets ===\n",
        "import requests\n",
        "def _cg_markets_fallback(vs=\"usd\", per_page=250, pages=1):\n",
        "    rows = []\n",
        "    headers = {\"Accept\":\"application/json\",\"User-Agent\":\"cg-screener/1.0\"}\n",
        "    base = \"https://api.coingecko.com/api/v3\"\n",
        "    for page in range(1, int(pages)+1):\n",
        "        params = {\n",
        "            \"vs_currency\": vs, \"order\": \"market_cap_desc\",\n",
        "            \"per_page\": int(per_page), \"page\": int(page),\n",
        "            \"sparkline\": \"false\", \"price_change_percentage\": \"7d,30d\"\n",
        "        }\n",
        "        r = requests.get(f\"{base}/coins/markets\", headers=headers, params=params, timeout=25)\n",
        "        if r.status_code != 200:\n",
        "            logging.warning(f\"[cg-fb] HTTP {r.status_code} /coins/markets page={page}\"); continue\n",
        "        try: data = r.json()\n",
        "        except Exception: data = []\n",
        "        if isinstance(data, list): rows.extend(data)\n",
        "    if not rows: return pd.DataFrame()\n",
        "    df = pd.json_normalize(rows, sep=\"_\")\n",
        "    want = [\"id\",\"symbol\",\"name\",\"market_cap\",\"total_volume\",\n",
        "            \"price_change_percentage_7d_in_currency\",\"price_change_percentage_30d_in_currency\",\n",
        "            \"ath_change_percentage\",\"circulating_supply\"]\n",
        "    return df[[c for c in want if c in df.columns]].copy()\n",
        "\n",
        "# === Konfiguration ===\n",
        "RUN_MODE = os.environ.get(\"RUN_MODE\", \"standard\").strip().lower()\n",
        "CFG = {\n",
        "    \"fast\":     {\"PAGES\":1, \"BREAKOUT_PER_SEGMENT\":{\"Hidden Gem\":30,\"Emerging\":20,\"Comeback\":15,\"Momentum Gem\":15,\"Balanced\":20}, \"BUZZ_TOPN\":120, \"DAYS\":180, \"USE_CP\":False, \"NEW_LISTINGS\":True,  \"BACKTEST\":False},\n",
        "    \"standard\": {\"PAGES\":4, \"BREAKOUT_PER_SEGMENT\":{\"Hidden Gem\":60,\"Emerging\":50,\"Comeback\":40,\"Momentum Gem\":40,\"Balanced\":40}, \"BUZZ_TOPN\":200, \"DAYS\":365, \"USE_CP\":True,  \"NEW_LISTINGS\":False, \"BACKTEST\":True}\n",
        "}[RUN_MODE]\n",
        "\n",
        "VS = os.environ.get(\"VS\", \"usd\")\n",
        "MIN_VOLUME_USD = float(os.environ.get(\"MIN_VOLUME_USD\", \"1000000\"))\n",
        "REQUIRE_MEXC = os.environ.get(\"REQUIRE_MEXC\", \"1\") == \"1\"\n",
        "SKIP_CATEGORIES = os.environ.get(\"SKIP_CATEGORIES\", \"0\") == \"1\"\n",
        "\n",
        "# LIGHT_BREAKOUT_ALL je Mode (env kann √ºbersteuern)\n",
        "LIGHT_BREAKOUT_ALL = True if RUN_MODE == \"fast\" else False\n",
        "_env_lba = os.environ.get(\"LIGHT_BREAKOUT_ALL\", None)\n",
        "if _env_lba in (\"0\",\"1\"):\n",
        "    LIGHT_BREAKOUT_ALL = (_env_lba == \"1\")\n",
        "\n",
        "USE_CRYPTOPANIC = CFG[\"USE_CP\"]\n",
        "CAP_MIN = 50_000_000\n",
        "CAP_MAX = 1_000_000_000\n",
        "\n",
        "# Zeitstempel (Berlin)\n",
        "from datetime import datetime as _dt\n",
        "try:\n",
        "    from zoneinfo import ZoneInfo\n",
        "    _TZ = ZoneInfo(\"Europe/Berlin\")\n",
        "except Exception:\n",
        "    _TZ = None\n",
        "_STAMP = (_dt.now(_TZ) if _TZ else _dt.now()).strftime(\"%Y-%m-%d - %H-%M\")\n",
        "EXPORT_NAME = f\"Scanner_v14_5_output_{RUN_MODE}_{_STAMP}.xlsx\"\n",
        "EXPORT_PATH = os.path.join(EXPORT_DIR, EXPORT_NAME)\n",
        "\n",
        "_pd.set_option(\"display.max_columns\", 160); _pd.set_option(\"display.width\", 220)\n",
        "\n",
        "# === Regime-Helper ===\n",
        "def _mom30_from_chart(prices):\n",
        "    if not prices or len(prices) < 31: return np.nan\n",
        "    p_now = float(prices[-1][1]); p_30 = float(prices[-31][1]); return (p_now/p_30 - 1.0)*100.0\n",
        "def _dd_pct(prices):\n",
        "    if not prices or len(prices) < 2: return np.nan\n",
        "    arr = [float(p[1]) for p in prices]; p_now = arr[-1]; p_max = max(arr); return (p_now/p_max - 1.0)*100.0 if p_max>0 else np.nan\n",
        "def _regime():\n",
        "    try:\n",
        "        btc = cg_market_chart(\"bitcoin\", vs=VS, days=max(365, CFG[\"DAYS\"]))\n",
        "        eth = cg_market_chart(\"ethereum\", vs=VS, days=max(365, CFG[\"DAYS\"]))\n",
        "        return {\"btc_mom30\": _mom30_from_chart(btc.get(\"prices\",[])),\n",
        "                \"btc_dd\": _dd_pct(btc.get(\"prices\",[])),\n",
        "                \"eth_mom30\": _mom30_from_chart(eth.get(\"prices\",[])),\n",
        "                \"eth_dd\": _dd_pct(eth.get(\"prices\",[]))}\n",
        "    except Exception as ex:\n",
        "        logging.warning(f\"[regime] {ex}\")\n",
        "        return {\"btc_mom30\": np.nan,\"btc_dd\": np.nan,\"eth_mom30\": np.nan,\"eth_dd\": np.nan}\n",
        "\n",
        "# =========================\n",
        "#          PIPELINE\n",
        "# =========================\n",
        "t_all = time.perf_counter()\n",
        "logging.info(f\"[0] Start {datetime.now(timezone.utc).isoformat()} | MODE={RUN_MODE} | PAGES={CFG['PAGES']}\")\n",
        "\n",
        "# [1] Universe (+Fallback)\n",
        "t0 = time.perf_counter()\n",
        "df = cg_markets(vs=VS, per_page=250, pages=CFG[\"PAGES\"])\n",
        "if df is None or df.empty:\n",
        "    logging.warning(\"[main] cg_markets leer ‚Üí Fallback nutzt direkten /coins/markets Abruf\")\n",
        "    df = _cg_markets_fallback(vs=VS, per_page=250, pages=CFG[\"PAGES\"])\n",
        "if df is None or df.empty:\n",
        "    raise RuntimeError(\"cg_markets leer (Fallback ebenfalls leer)\")\n",
        "logging.info(f\"[1] M√§rkte: {len(df)} Zeilen in {time.perf_counter()-t0:.2f}s\")\n",
        "print(\"Input-Spalten (price_change_*):\", [c for c in df.columns if \"price_change_percentage\" in c])\n",
        "\n",
        "# [2] Pre + Cap-Range\n",
        "t0 = time.perf_counter()\n",
        "df = apply_pre_universe_filters(df, min_volume_usd=MIN_VOLUME_USD)\n",
        "df[\"market_cap\"] = pd.to_numeric(df[\"market_cap\"], errors=\"coerce\")\n",
        "df = df[(df[\"market_cap\"] >= CAP_MIN) & (df[\"market_cap\"] <= CAP_MAX)].copy()\n",
        "logging.info(f\"[2] Pre+CapRange: √ºbrig {len(df)} in {time.perf_counter()-t0:.2f}s\")\n",
        "\n",
        "# [3] MEXC\n",
        "t0 = time.perf_counter()\n",
        "df = apply_mexc_filter(df, require_mexc=REQUIRE_MEXC)\n",
        "try: export_mexc_seed_template(df, collisions_only=True)\n",
        "except Exception: pass\n",
        "if len(df) == 0 and REQUIRE_MEXC:\n",
        "    raise RuntimeError(\"Nach MEXC-Schnitt 0 Zeilen.\")\n",
        "logging.info(f\"[3] MEXC ok: {len(df)} in {time.perf_counter()-t0:.2f}s\")\n",
        "\n",
        "# Optional: New Listings\n",
        "if CFG.get(\"NEW_LISTINGS\", False):\n",
        "    _ = update_seen_ids(df[\"id\"].astype(str).tolist())\n",
        "\n",
        "# [4] Kategorien (Hybrid, CG NICHT bevorzugt) + TVL\n",
        "t0 = time.perf_counter()\n",
        "if os.getenv(\"SKIP_CATEGORIES\",\"0\") != \"1\":\n",
        "    df_tmp = df.copy()\n",
        "    df_tmp[\"Segment\"] = df_tmp.apply(tag_segment, axis=1)\n",
        "    df_tmp[\"market_cap\"] = pd.to_numeric(df_tmp[\"market_cap\"], errors=\"coerce\")\n",
        "    df_tmp = df_tmp.sort_values(\"market_cap\", ascending=True)\n",
        "    seg_quota_for_cats = {\"Hidden Gem\":120, \"Emerging\":90, \"Comeback\":50, \"Momentum Gem\":30, \"Balanced\":10}\n",
        "    ids_cat = []\n",
        "    for seg, q in seg_quota_for_cats.items():\n",
        "        ids_cat.extend(df_tmp[df_tmp[\"Segment\"]==seg].head(q)[\"id\"].astype(str).tolist())\n",
        "    if len(ids_cat) < 300:\n",
        "        extra = df_tmp[~df_tmp[\"id\"].astype(str).isin(ids_cat)].head(300 - len(ids_cat))\n",
        "        ids_cat.extend(extra[\"id\"].astype(str).tolist())\n",
        "    ids_cat = list(dict.fromkeys(ids_cat))[:300]\n",
        "    df.attrs[\"asof_date\"] = ASOF_DATE\n",
        "    cat_map = enrich_categories_hybrid(df, ids_cat, ttl_days=14, max_fetch=200, prefer_cg_first=False)\n",
        "    df[\"Kategorie\"] = df[\"id\"].astype(str).map(cat_map).fillna(\"Unknown\")\n",
        "else:\n",
        "    df[\"Kategorie\"] = \"Unknown\"\n",
        "df = map_tvl(df)\n",
        "logging.info(f\"[4] Kategorien/TVL ok in {time.perf_counter()-t0:.2f}s\")\n",
        "\n",
        "# [5] Features\n",
        "t0 = time.perf_counter()\n",
        "df = compute_feature_block(df)\n",
        "logging.info(f\"[5] Features ok in {time.perf_counter()-t0:.2f}s\")\n",
        "print(\"Nach Features‚ÄëBlock:\", df.columns.tolist()[:50])\n",
        "print(\"Spaltenpreise:\", [c for c in df.columns if \"price_change_percentage\" in c])\n",
        "\n",
        "# [6] Segmente\n",
        "df[\"Segment\"] = df.apply(tag_segment, axis=1)\n",
        "\n",
        "# [7] Regime\n",
        "regime_info = _regime()\n",
        "\n",
        "# [8] Peg/Wrapped/Stable-Maske\n",
        "peg_mask = exclusion_mask(df, df.get(\"Kategorie\", pd.Series()))\n",
        "\n",
        "# [9] Scores\n",
        "df = score_block(df, regime_info=regime_info)\n",
        "\n",
        "# [10] Early Pass1\n",
        "df_p1 = df.copy()\n",
        "df_p1[\"breakout_score\"] = np.nan\n",
        "df_p1[\"vol_acc\"] = 1.0\n",
        "df_p1 = compute_early_score(df_p1, peg_mask=peg_mask, regime_info=regime_info)\n",
        "df[\"early_prelim\"] = df_p1[\"early_score\"]\n",
        "\n",
        "# [11] Kandidaten\n",
        "def _pick_candidates(dfin, per_segment):\n",
        "    out=[]\n",
        "    for s, n in per_segment.items():\n",
        "        sub = dfin[dfin[\"Segment\"]==s].copy()\n",
        "        if sub.empty: continue\n",
        "        sub = sub.sort_values([\"early_prelim\",\"score_segment\"], ascending=[False,False]).head(int(n))\n",
        "        out.append(sub)\n",
        "    return pd.concat(out, ignore_index=True) if out else dfin.head(0)\n",
        "if LIGHT_BREAKOUT_ALL:\n",
        "    cand_ids = df.loc[~df[\"mexc_pair\"].isna(), \"id\"].astype(str).tolist()\n",
        "else:\n",
        "    cand_ids = _pick_candidates(df, CFG[\"BREAKOUT_PER_SEGMENT\"])[\"id\"].astype(str).tolist()\n",
        "\n",
        "# [12] Breakout\n",
        "t0 = time.perf_counter()\n",
        "br = compute_breakout_for_ids(df, cand_ids, days=CFG[\"DAYS\"], progress=True, light=bool(LIGHT_BREAKOUT_ALL))\n",
        "if isinstance(br, pd.DataFrame) and not br.empty:\n",
        "    df = df.merge(br, on=\"id\", how=\"left\")\n",
        "else:\n",
        "    for c in [\"dist_90\",\"dist_180\",\"dist_365\",\"p365\",\"donch_width\",\"vol_acc\",\"vol_acc_7d\",\"vol_acc_30d\",\"z_break\",\"z_donch\",\"breakout_score\",\"beta_btc\",\"beta_eth\",\"break_vol_mult\",\"price_source\"]:\n",
        "        if c not in df.columns: df[c] = np.nan\n",
        "df[\"price_source\"] = df[\"price_source\"].fillna(\"cg\")\n",
        "logging.info(f\"[12] Breakout ok in {time.perf_counter()-t0:.2f}s\")\n",
        "\n",
        "# [13] Buzz\n",
        "t0 = time.perf_counter()\n",
        "df = add_buzz_metrics_for_candidates(\n",
        "    df_in=df,\n",
        "    top_n=min(CFG[\"BUZZ_TOPN\"], len(df)),\n",
        "    use_cp=USE_CRYPTOPANIC,\n",
        "    mask_pegged=peg_mask,\n",
        "    rss_news=None,\n",
        "    cp_api_key=os.getenv(\"CRYPTOPANIC_API_KEY\")\n",
        ")\n",
        "logging.info(f\"[13] Buzz ok in {time.perf_counter()-t0:.2f}s\")\n",
        "\n",
        "# [14] Early final\n",
        "t0 = time.perf_counter()\n",
        "df = compute_early_score(df, peg_mask=peg_mask, regime_info=regime_info)\n",
        "logging.info(f\"[14] Early final ok in {time.perf_counter()-t0:.2f}s\")\n",
        "\n",
        "# [15] Rankings\n",
        "def _keep_cols(dfin, extra=None):\n",
        "    base = [\"id\",\"symbol\",\"name\",\"Segment\",\"market_cap\",\"total_volume\",\"mexc_pair\",\"score_global\",\"score_segment\",\"early_score\"]\n",
        "    ext = extra or []\n",
        "    cols = [c for c in base+ext if c in dfin.columns]\n",
        "    return dfin[cols].copy()\n",
        "top25_global = df.sort_values(\"score_global\", ascending=False).head(25)\n",
        "top25_early  = df.sort_values(\"early_score\", ascending=False).head(25)\n",
        "seg_names = [\"Hidden Gem\",\"Emerging\",\"Comeback\",\"Momentum Gem\",\"Balanced\"]\n",
        "top10_segments = {}\n",
        "for s in seg_names:\n",
        "    sub = df[df[\"Segment\"]==s].copy()\n",
        "    if not sub.empty: top10_segments[s] = sub.sort_values(\"early_score\", ascending=False).head(10)\n",
        "top10_all = pd.concat([v for v in top10_segments.values()], ignore_index=True) if top10_segments else df.head(0)\n",
        "\n",
        "# [16] FullData (mit Buzz-Spalten)\n",
        "print(\"mom_7d_pct in df:\", \"mom_7d_pct\" in df.columns)\n",
        "print(\"mom_30d_pct in df:\", \"mom_30d_pct\" in df.columns)\n",
        "full_data = make_fulldata(df)\n",
        "print(\"mom_7d_pct in full_data:\", \"mom_7d_pct\" in full_data.columns)\n",
        "print(\"mom_30d_pct in full_data:\", \"mom_30d_pct\" in full_data.columns)\n",
        "\n",
        "# [17] Backtest\n",
        "bt = pd.DataFrame()\n",
        "if CFG.get(\"BACKTEST\", False):\n",
        "    bt = backtest_on_snapshot(df.sort_values(\"early_score\", ascending=False), topk=20, days_list=[20,40,60], vs=VS)\n",
        "\n",
        "# [18] Meta\n",
        "from datetime import datetime as _dtu\n",
        "meta = {\n",
        "    \"version\": f\"v14.5-{RUN_MODE}\",\n",
        "    \"vs\": VS,\n",
        "    \"min_volume_usd\": str(int(MIN_VOLUME_USD)),\n",
        "    \"cap_min\": str(CAP_MIN),\n",
        "    \"cap_max\": str(CAP_MAX),\n",
        "    \"pages\": str(CFG[\"PAGES\"]),\n",
        "    \"breakout_per_segment\": str(CFG[\"BREAKOUT_PER_SEGMENT\"]),\n",
        "    \"buzz_topn\": str(CFG[\"BUZZ_TOPN\"]),\n",
        "    \"days\": str(CFG[\"DAYS\"]),\n",
        "    \"use_cryptopanic\": str(USE_CRYPTOPANIC),\n",
        "    \"require_mexc\": str(REQUIRE_MEXC),\n",
        "    \"light_breakout_all\": \"1\" if LIGHT_BREAKOUT_ALL else \"0\",\n",
        "    \"allow_cg_fallback\": os.getenv(\"ALLOW_CG_FALLBACK\",\"0\"),\n",
        "    \"buzz_half_life_h\": os.getenv(\"BUZZ_HALF_LIFE_H\",\"48\"),\n",
        "    \"publisher_weights\": os.getenv(\"BUZZ_PUBLISHER_WEIGHTS\",\"{}\"),\n",
        "    \"timestamp_utc\": _dtu.now(timezone.utc).isoformat(),\n",
        "}\n",
        "\n",
        "# [19] Export\n",
        "with pd.ExcelWriter(EXPORT_PATH, engine=\"xlsxwriter\") as w:\n",
        "    write_sheet(top25_global, \"Top25_Global\", w)\n",
        "    for s, dseg in top10_segments.items():\n",
        "        write_sheet(dseg, f\"Top10_{s.replace(' ', '_')}\", w)\n",
        "    if not top10_all.empty:\n",
        "        write_sheet(top10_all, \"Top10_AllSegments\", w)\n",
        "    write_sheet(top25_early, \"Top25_EarlySignals\", w)\n",
        "    write_sheet(full_data, \"FullData\", w)\n",
        "    if CFG.get(\"BACKTEST\", False) and not bt.empty:\n",
        "        write_sheet(bt, \"Backtest\", w)\n",
        "    write_meta_sheet(w, meta)\n",
        "\n",
        "# ------------------\n",
        "# [20] Neuer Export in kryptotreiber Google Drive\n",
        "import os\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "def upload_to_drive(service_account_file: str, folder_id: str, local_file_path: str):\n",
        "    credentials = service_account.Credentials.from_service_account_file(\n",
        "        service_account_file,\n",
        "        scopes=[\"https://www.googleapis.com/auth/drive\"]\n",
        "    )\n",
        "    service = build(\"drive\", \"v3\", credentials=credentials)\n",
        "\n",
        "    file_metadata = {\n",
        "        \"name\": os.path.basename(local_file_path),\n",
        "        \"parents\": [folder_id]\n",
        "    }\n",
        "    media = MediaFileUpload(local_file_path, resumable=True)\n",
        "    uploaded_file = service.files().create(\n",
        "        body=file_metadata,\n",
        "        media_body=media,\n",
        "        fields=\"id\"\n",
        "    ).execute()\n",
        "\n",
        "    print(f\"‚úÖ Datei hochgeladen ‚Äì File ID: {uploaded_file.get('id')}\")\n",
        "\n",
        "# Aufruf aus Notebook\n",
        "# Beispielpfade anpassen:\n",
        "SERVICE_ACCOUNT_FILE = \"/content/crypto-drive-export-96ab6bcd019b.json\"  # Pfad zur JSON-Datei\n",
        "FOLDER_ID = \"1Kl29WBUsWBLPMcDyBZ9WBRAvSNzpjSkd\"  # Deine Drive-Ordner-ID\n",
        "EXPORT_FILE = EXPORT_PATH  # Verweist auf die tats√§chlich erzeugte Datei\n",
        "\n",
        "upload_to_drive(SERVICE_ACCOUNT_FILE, FOLDER_ID, EXPORT_FILE)\n",
        "\n",
        "# Ende neuer Export\n",
        "# ------------------\n",
        "\n",
        "print(\"Export:\", EXPORT_PATH)\n",
        "import os\n",
        "print(\"EXISTIERT:\", os.path.exists(EXPORT_PATH))\n",
        "print(\"EXPORT_PATH:\", EXPORT_PATH)\n",
        "\n",
        "try:\n",
        "    display(top25_early.head(10)); display(full_data.head(10))\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/snapshots/exports\n"
      ],
      "metadata": {
        "id": "lpMr65iaEkvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S1S6COThj1wC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}